library(readr)
CWTme_mh_APO_001_CWT_features <- read_csv("Documents/Thesis-Stroke/StatisticalAnalysis/CWT/CWTme_mh_APO-001_CWT_features.csv")
View(CWTme_mh_APO_001_CWT_features)
data <- CWTme_mh_APO_001_CWT_features
install.packages('dplyr')
library(dplyr)
data$Label <- factor(data$Label)
data$Stage <- factor(data$Stage)
tst <- data[data$Stage == '1', data$Freq_name = 'Delta']
tst <- data[data$Stage == '1', data$Freq_name == 'Delta',]
tst <- data[data$Stage == '1' & data$Freq_name == 'Delta',]
tst.mean <- group_by(data = tst, add = 'mean')
tst.mean <- group_by(.data = data)
tst.mean <- group_by(.data = data, add = mean())
tst.mean <- group_by(.data = data, add = mean
)
tst.mean <- group_by(.data = data, add = 'mean')
aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
data.agg <- aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
View(data.agg)
data$Chann_name <- factor(data$Chann_name)
data$ID_pat <- factor(data$ID_pat)
data$Freq_name <- factor(data$Freq_name)
data.agg <- aggregate(x = data, by = list(ID_pat = data$ID_pat, Stage = data$Stage, Chann_name = data$Chann_name, Freq_name = data$Freq_name), FUN = mean)
View(data.agg)
data.agg <- aggregate(x = data, by = list(data$Freq_name, data$ID_pat, data$Stage, data$Chann_name), FUN = mean)
library(readr)
me_mh_APO_001_CWT_features <- read_csv("Downloads/me_mh_APO-001_CWT_features.csv")
View(me_mh_APO_001_CWT_features)
CWTme_mh_APO_001_CWT_features$Chann_name <- factor(CWTme_mh_APO_001_CWT_features$Chann_name)
install.packages('xlsx')
install.packages('xlsxjars')
install.packages('xlsx')
setInternet2(use=TRUE)
install.packages('rJava')
remove.packages("rJava")
install.packages('rJava')
install.packages('rJava')
install.packages('xlsx')
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
install.packages('xlsx')
install.packages('xlsxjars')
install.packages('xlsxjars')
install.packages('rJava')
library(rJava)
remove.packages('rJava')
remove.packages(rJava)
install.packages('rJava')
install.packages('rJava')
library(rJava)
library(rJava)
library(rJava)
install.packages('rJava')
install.packages('rJava')
install.packages('rJava')
locate getsp
install.packages('rJava')
remove.packages('rJava')
library(rJava)
install.packages('rJava')
# Import libraries
library(jsonlite)
library(tidyverse)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(corrplot)
library(randomForest)
library(xlsx)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(ggplot2)
library(gridExtra)
library(rlist)
########## IMPORT ##########
setwd("~/Documents/GWAS_pipeline")
# Import settings
settings <- jsonlite::fromJSON('settings.json')
# Load pre-fit model and comvert to hlaMODEL
model.list <- get(load(settings$file$PMRA_HLA_model))
hla.id <- names(model.list)
# Import file
gname <- settings$plinkFiles$GWASQC
yourgeno <- hlaBED2Geno(bed.fn=paste(gname, ".bed", sep = ''), fam.fn=paste(gname, ".fam", sep='')
, bim.fn=paste(gname, ".bim", sep=''), assembly = 'hg19')
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(ggplot2)
library(gridExtra)
library(rlist)
########## IMPORT ##########
setwd("~/Documents/GWAS_pipeline")
# Import settings
settings <- jsonlite::fromJSON('settings.json')
# Load pre-fit model and comvert to hlaMODEL
model.list <- get(load(settings$file$PMRA_HLA_model))
hla.id <- names(model.list)
# Import file
gname <- settings$plinkFiles$GWASQC
yourgeno <- hlaBED2Geno(bed.fn=paste(gname, ".bed", sep = ''), fam.fn=paste(gname, ".fam", sep='')
, bim.fn=paste(gname, ".bim", sep=''), assembly = 'hg19')
summary(yourgeno)
# Make cluster
cl <- makeCluster(10)
# Make predictions
for (locus in hla.id){
model.hla <- hlaModelFromObj(model.list[[locus]])
summary(model.hla)
pred.guess <- predict(model.hla, yourgeno, type="response+prob", nclassifiers=100, cl=cl)
save(pred.guess, file = paste(settings$directory$HLA_Imputation, paste('HLA_', locus, sep = ''), '.RData', sep= ''))
}
# Initialize loop# List of files to merge
file.names <- list.files(settings$directory$HLA_Imputation)
# First pass
f <- file.names[1]
load(paste0(settings$directory$HLA_Imputation, f)) %>% .['value']
HLA.data <- pred.guess$value
# Get probs and alleles
probs.data <- HLA.data[,c(1,4)]
HLA.data <- HLA.data[,1:3]
colnames(HLA.data) <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs.data) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge rest of files
for (f in file.names[2:length(file.names)]){
# Print for loop
print(paste0("Current file: ", f))
# Load file
load(paste0(settings$directory$HLA_Imputation, f))
data <- pred.guess$value[,c(1:3)]
probs <- pred.guess$value[,c(1,4)]
colnames(data)[1:3] <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge by sample.id
HLA.data <- merge(HLA.data, data, by = "sample.id")
# Merge probs by sample.id
probs.data <- merge(probs.data, probs, by = "sample.id")
}
# Write
write.table(HLA.data, file = settings$file$HLA_calls, sep = ',', quote = FALSE, row.names = FALSE, col.names = TRUE)
write.table(probs.data, file = settings$file$HLA_probs, sep = ',', quote = FALSE, row.names = FALSE, col.names = TRUE)
# Plot probabilities
pl <- vector('list', ncol(probs.data)-1)
settings$file$HLA_probs
# Import settings
settings <- jsonlite::fromJSON('settings.json')
write.table(probs.data, file = settings$file$HLA_probs, sep = ',', quote = FALSE, row.names = FALSE, col.names = TRUE)
# Plot probabilities
pl <- vector('list', ncol(probs.data)-1)
idx <- 1
for (i in 2:ncol(probs.data)){
pl[[i-1]] <- local({
i <- i
p1 <- ggplot(probs.data, aes(get(colnames(probs.data)[i]))) +
geom_histogram() +
xlab(colnames(probs.data)[i]) + xlim(0,1)
print(p1)
})
}
do.call(grid.arrange, pl)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(ggplot2)
library(gridExtra)
library(rlist)
########## IMPORT ##########
setwd("~/Documents/GWAS_pipeline")
# Import settings
settings <- jsonlite::fromJSON('settings.json')
# Load pre-fit model and comvert to hlaMODEL
model.list <- get(load(settings$file$PMRA_HLA_model))
hla.id <- names(model.list)
# Import file
gname <- settings$plinkFiles$GWASQC
yourgeno <- hlaBED2Geno(bed.fn=paste(gname, ".bed", sep = ''), fam.fn=paste(gname, ".fam", sep='')
, bim.fn=paste(gname, ".bim", sep=''), assembly = 'hg19')
summary(yourgeno)
# Make cluster
cl <- makeCluster(10)
# Make predictions
for (locus in hla.id){
model.hla <- hlaModelFromObj(model.list[[locus]])
summary(model.hla)
pred.guess <- predict(model.hla, yourgeno, type="response+prob", nclassifiers=100, cl=cl)
save(pred.guess, file = paste(settings$directory$HLA_Imputation, paste('HLA_', locus, sep = ''), '.RData', sep= ''))
}
# Initialize loop# List of files to merge
file.names <- list.files(settings$directory$HLA_Imputation)
file.names
file.names
# First pass
f <- file.names[1]
load(paste0(settings$directory$HLA_Imputation, f)) %>% .['value']
HLA.data <- pred.guess$value
HLA_Imputation
settings$directory$HLA_Imputation
load(paste0(settings$directory$HLA_Imputation, f))
%>% .['value']
HLA.data <- pred.guess$value
View(HLA.data)
View(pred.guess)
# Import libraries
library(jsonlite)
library(tidyverse)
library(readr)
library(data.table)
library(ggrepel)
library(viridis)
library(hrbrthemes)
library(HIBAG)
library(parallel)
library(ggplot2)
library(gridExtra)
library(rlist)
########## IMPORT ##########
setwd("~/Documents/GWAS_pipeline")
# Import settings
settings <- jsonlite::fromJSON('settings.json')
# Load pre-fit model and comvert to hlaMODEL
model.list <- get(load(settings$file$PMRA_HLA_model))
hla.id <- names(model.list)
# Import file
gname <- settings$plinkFiles$GWASQC
yourgeno <- hlaBED2Geno(bed.fn=paste(gname, ".bed", sep = ''), fam.fn=paste(gname, ".fam", sep='')
, bim.fn=paste(gname, ".bim", sep=''), assembly = 'hg19')
gname
summary(yourgeno)
# Make cluster
cl <- makeCluster(10)
# Make predictions
for (locus in hla.id){
model.hla <- hlaModelFromObj(model.list[[locus]])
summary(model.hla)
pred.guess <- predict(model.hla, yourgeno, type="response+prob", nclassifiers=100, cl=cl)
save(pred.guess, file = paste(settings$directory$HLA_Imputation, paste('HLA_', locus, sep = ''), '.RData', sep= ''))
}
# Initialize loop# List of files to merge
file.names <- list.files(settings$directory$HLA_Imputation)
# First pass
f <- file.names[1]
load(paste0(settings$directory$HLA_Imputation, f))
HLA.data <- pred.guess$value
View(HLA.data)
# Get probs and alleles
probs.data <- HLA.data[,c(1,4)]
HLA.data <- HLA.data[,1:3]
colnames(HLA.data) <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs.data) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge rest of files
for (f in file.names[2:length(file.names)]){
# Print for loop
print(paste0("Current file: ", f))
# Load file
load(paste0(settings$directory$HLA_Imputation, f))
data <- pred.guess$value[,c(1:3)]
probs <- pred.guess$value[,c(1,4)]
colnames(data)[1:3] <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge by sample.id
HLA.data <- merge(HLA.data, data, by = "sample.id")
# Merge probs by sample.id
probs.data <- merge(probs.data, probs, by = "sample.id")
}
f
# Initialize loop# List of files to merge
file.names <- list.files(settings$directory$HLA_Imputation)
file.names <- file.names[which(grepl(x=file.namesm, pattern = '.RData'))]
# First pass
f <- file.names[1]
file.names <- file.names[which(grepl(x=file.names, pattern = '.RData'))]
# First pass
f <- file.names[1]
load(paste0(settings$directory$HLA_Imputation, f))
HLA.data <- pred.guess$value
# Get probs and alleles
probs.data <- HLA.data[,c(1,4)]
HLA.data <- HLA.data[,1:3]
colnames(HLA.data) <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs.data) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge rest of files
for (f in file.names[2:length(file.names)]){
# Print for loop
print(paste0("Current file: ", f))
# Load file
load(paste0(settings$directory$HLA_Imputation, f))
data <- pred.guess$value[,c(1:3)]
probs <- pred.guess$value[,c(1,4)]
colnames(data)[1:3] <- c("sample.id", paste0(pred.guess$locus, '.1'), paste0(pred.guess$locus, '.2'))
colnames(probs) <- c("sample.id", paste0("prob.", pred.guess$locus))
# Merge by sample.id
HLA.data <- merge(HLA.data, data, by = "sample.id")
# Merge probs by sample.id
probs.data <- merge(probs.data, probs, by = "sample.id")
}
# Write
write.table(HLA.data, file = settings$file$HLA_calls, sep = ',', quote = FALSE, row.names = FALSE, col.names = TRUE)
write.table(probs.data, file = settings$file$HLA_probs, sep = ',', quote = FALSE, row.names = FALSE, col.names = TRUE)
# Plot probabilities
pl <- vector('list', ncol(probs.data)-1)
idx <- 1
for (i in 2:ncol(probs.data)){
pl[[i-1]] <- local({
i <- i
p1 <- ggplot(probs.data, aes(get(colnames(probs.data)[i]))) +
geom_histogram() +
xlab(colnames(probs.data)[i]) + xlim(0,1)
print(p1)
})
}
do.call(grid.arrange, pl)
View(HLA.data)
